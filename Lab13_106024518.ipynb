{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab13 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stat_pc\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "#import spacy\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "#word_apple = nlp('apple')\n",
    "#word_banana = nlp('banana')\n",
    "#word_mac = nlp('mac')\n",
    "#print('%s vs %s: %.6f'%(word_apple, word_banana, word_apple.similarity(word_banana)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id2line():\n",
    "    lines=open('dataset/chatbot/movie_lines.txt', 'r', encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "    id2line = {}\n",
    "    for line in lines:\n",
    "        _line = line.split(' +++$+++ ')\n",
    "        if len(_line) == 5:\n",
    "            id2line[_line[0]] = _line[4]\n",
    "    return id2line\n",
    "\n",
    "'''\n",
    "    1. Read from 'movie_conversations.txt'\n",
    "    2. Create a list of [list of line_id's]\n",
    "'''\n",
    "def get_conversations():\n",
    "    conv_lines = open('dataset/chatbot/movie_conversations.txt').read().split('\\n')\n",
    "    convs = [ ]\n",
    "    for line in conv_lines[:-1]:\n",
    "        _line = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n",
    "        convs.append(_line.split(','))\n",
    "    return convs\n",
    "\n",
    "'''\n",
    "    1. Get each conversation\n",
    "    2. Get each line from conversation\n",
    "    3. Save each conversation to file\n",
    "'''\n",
    "def extract_conversations(convs,id2line,path=''):\n",
    "    idx = 0\n",
    "    for conv in convs:\n",
    "        f_conv = open(path + str(idx)+'.txt', 'w')\n",
    "        for line_id in conv:\n",
    "            f_conv.write(id2line[line_id])\n",
    "            f_conv.write('\\n')\n",
    "        f_conv.close()\n",
    "        idx += 1\n",
    "\n",
    "'''\n",
    "    Get lists of all conversations as Questions and Answers\n",
    "    1. [questions]\n",
    "    2. [answers]\n",
    "'''\n",
    "def gather_dataset(convs, id2line):\n",
    "    questions = []; answers = []\n",
    "\n",
    "    for conv in convs:\n",
    "        if len(conv) %2 != 0:\n",
    "            conv = conv[:-1]\n",
    "        for i in range(len(conv)):\n",
    "            if i%2 == 0:\n",
    "                questions.append(id2line[conv[i]])\n",
    "            else:\n",
    "                answers.append(id2line[conv[i]])\n",
    "\n",
    "    return questions, answers\n",
    "\n",
    "def prepare_seq2seq_files(questions, answers, path='',TESTSET_SIZE = 10000):\n",
    "    \n",
    "    # open files\n",
    "    train_enc = open(path + 'train.enc','w')\n",
    "    train_dec = open(path + 'train.dec','w')\n",
    "    test_enc  = open(path + 'test.enc', 'w')\n",
    "    test_dec  = open(path + 'test.dec', 'w')\n",
    "\n",
    "    # choose 30,000 (TESTSET_SIZE) items to put into testset\n",
    "    test_ids = random.sample([i for i in range(len(questions))],TESTSET_SIZE)\n",
    "\n",
    "    for i in range(len(questions)):\n",
    "        if i in test_ids:\n",
    "            test_enc.write(questions[i]+'\\n')\n",
    "            test_dec.write(answers[i]+ '\\n' )\n",
    "        else:\n",
    "            train_enc.write(questions[i]+'\\n')\n",
    "            train_dec.write(answers[i]+ '\\n' )\n",
    "        if i%10000 == 0:\n",
    "            print ('\\n>> written %d lines' %(i) )\n",
    "\n",
    "    # close files\n",
    "    train_enc.close()\n",
    "    train_dec.close()\n",
    "    test_enc.close()\n",
    "    test_dec.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> gathered id2line dictionary.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load lines dictionary \n",
    "lines = open('dataset/chatbot/movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "\n",
    "# load conversations\n",
    "convs = open('dataset/chatbot/movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "\n",
    "id2line = get_id2line()\n",
    "convers = get_conversations()\n",
    "\n",
    "print ('>> gathered id2line dictionary.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 還原對話"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = gather_dataset(convers,id2line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n"
     ]
    }
   ],
   "source": [
    "print (questions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well, I thought we'd start with pronunciation, if that's okay with you.\n"
     ]
    }
   ],
   "source": [
    "print (answers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 製造traing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> written 0 lines\n",
      "\n",
      ">> written 10000 lines\n",
      "\n",
      ">> written 20000 lines\n",
      "\n",
      ">> written 30000 lines\n",
      "\n",
      ">> written 40000 lines\n",
      "\n",
      ">> written 50000 lines\n",
      "\n",
      ">> written 60000 lines\n",
      "\n",
      ">> written 70000 lines\n",
      "\n",
      ">> written 80000 lines\n",
      "\n",
      ">> written 90000 lines\n",
      "\n",
      ">> written 100000 lines\n",
      "\n",
      ">> written 110000 lines\n",
      "\n",
      ">> written 120000 lines\n",
      "\n",
      ">> written 130000 lines\n"
     ]
    }
   ],
   "source": [
    "prepare_seq2seq_files(questions,answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enc = open('train.enc','r').read().split('\\n') #question for train\n",
    "train_dec = open('train.dec','r').read().split('\\n') #answer for train\n",
    "test_enc = open('test.enc','r').read().split('\\n') #question for test\n",
    "test_dec = open('test.enc','r').read().split('\\n')#answer for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.', 'Not the hacking and gagging and spitting part.  Please.', \"You're asking me out.  That's so cute. What's your name again?\", \"No, no, it's my fault -- we didn't have a proper introduction ---\", \"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\"]\n"
     ]
    }
   ],
   "source": [
    "print(train_enc[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加上  BEG END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enc_new=[]\n",
    "train_dec_new=[]\n",
    "test_enc_new=[]\n",
    "test_dec_new=[]\n",
    "for i in train_enc:\n",
    "    train_enc_new.append('<BEG>'+' '+ i +' '+'<END>')\n",
    "\n",
    "for i in train_dec:\n",
    "    train_dec_new.append('<BEG>'+' '+ i +' '+'<END>')\n",
    "\n",
    "for i in test_enc:\n",
    "    test_enc_new.append('<BEG>'+' '+ i +' '+'<END>')\n",
    "\n",
    "for i in test_dec:\n",
    "    test_dec_new.append('<BEG>'+' '+ i +' '+'<END>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<BEG> Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. <END>', '<BEG> Not the hacking and gagging and spitting part.  Please. <END>', \"<BEG> You're asking me out.  That's so cute. What's your name again? <END>\", \"<BEG> No, no, it's my fault -- we didn't have a proper introduction --- <END>\", \"<BEG> The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does. <END>\"]\n"
     ]
    }
   ],
   "source": [
    "print(train_enc_new[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 128136 \n",
      " 128136\n"
     ]
    }
   ],
   "source": [
    "print('',len(train_enc_new),'\\n',len(train_dec_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 轉label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "qq1 = np.array([f for f in range(3200,4000)]+[f for f in range(1590,2000)]+[f for f in range(3850,3900)]+[f for f in range(5700,5900)]+ [f for f in range(30600,30700)]+[f for f in range(67100,67300)]+[f for f in range(53820,53900)]+[f for f in range(54792,54900)]+[f for f in range(118903,119200)]+[f for f in range(91450,91500)]+[f for f in range(75630,75650)])\n",
    "train=[]  \n",
    "\n",
    "for j in qq1:\n",
    "    train.append(train_enc_new[j])\n",
    "\n",
    "for j in qq1:\n",
    "    train.append(train_dec_new[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將字全部轉出來 ----> vob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "vob={'<BEG>':0,'<END>':1,'<PAD>':2}\n",
    "id=3\n",
    "for line in train:\n",
    "    tline=line.split()\n",
    "    for token in tline:\n",
    "        if  token not in vob:\n",
    "            vob[token]=id\n",
    "            id=id+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  反函數 Vob_rev [ Number ] -->Str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "vob_rev={}\n",
    "for key ,value in list(vob.items()):\n",
    "    vob_rev[value]=key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1621\n",
      "2271\n",
      "2296\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train)):\n",
    "    if train[i]=='<BEG> You look great. <END>':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vob[ Str ]--->Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_corpus=[]\n",
    "answer_corpus=[]\n",
    "for w,l in zip(train[0:2315],train[2315:4630]):\n",
    "    s=[vob[j] for j in w.split()]\n",
    "    p=[vob[j] for j in l.split()]\n",
    "    if len(s)<11 :\n",
    "        if len(p)<11:\n",
    "            question_corpus.append(s)\n",
    "            answer_corpus.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 看資料的長度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "question_corpus_max = 0\n",
    "answer_corpus_max = 0\n",
    "\n",
    "for i in range(len(question_corpus)):\n",
    "    # caculate max length\n",
    "    question_corpus_max = max(question_corpus_max, len(question_corpus[i]))\n",
    "    answer_corpus_max = max(answer_corpus_max, len(answer_corpus[i]))\n",
    "\n",
    "print(question_corpus_max, answer_corpus_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "\n",
    "  def __init__(self, en_corpus, ch_corpus, en_pad, ch_pad, en_max_len,\n",
    "               ch_max_len, batch_size):\n",
    "    n = len(en_corpus)\n",
    "    batch_num = len(en_corpus) // batch_size\n",
    "    n = batch_num * batch_size\n",
    "\n",
    "    self.xs = [np.zeros(n, dtype=np.int32)\n",
    "               for _ in range(en_max_len)]  # encoder inputs\n",
    "    self.ys = [np.zeros(n, dtype=np.int32)\n",
    "               for _ in range(ch_max_len)]  # decoder inputs\n",
    "    self.gs = [np.zeros(n, dtype=np.int32)\n",
    "               for _ in range(ch_max_len)]  # decoder outputs\n",
    "    self.ws = [np.zeros(n, dtype=np.float32)\n",
    "               for _ in range(ch_max_len)]  # decoder weight for loss caculation\n",
    "\n",
    "    self.en_max_len = en_max_len\n",
    "    self.ch_max_len = ch_max_len\n",
    "    self.batch_size = batch_size\n",
    "\n",
    "    for b in range(batch_num):\n",
    "      for i in range(b * batch_size, (b + 1) * batch_size):\n",
    "        for j in range(len(en_corpus[i]) - 2):\n",
    "          self.xs[j][i] = en_corpus[i][j + 1]\n",
    "        for j in range(j + 1, en_max_len):\n",
    "          self.xs[j][i] = en_pad\n",
    "\n",
    "        for j in range(len(ch_corpus[i]) - 1):\n",
    "          self.ys[j][i] = ch_corpus[i][j]\n",
    "          self.gs[j][i] = ch_corpus[i][j + 1]\n",
    "          self.ws[j][i] = 1.0\n",
    "        for j in range(\n",
    "            j + 1, ch_max_len):  # don't forget padding and let loss weight zero\n",
    "          self.ys[j][i] = ch_pad\n",
    "          self.gs[j][i] = ch_pad\n",
    "          self.ws[j][i] = 0.0\n",
    "\n",
    "  def get(self, batch_id):\n",
    "    x = [\n",
    "        self.xs[i][batch_id * self.batch_size:(batch_id + 1) * self.batch_size]\n",
    "        for i in range(self.en_max_len)\n",
    "    ]\n",
    "    y = [\n",
    "        self.ys[i][batch_id * self.batch_size:(batch_id + 1) * self.batch_size]\n",
    "        for i in range(self.ch_max_len)\n",
    "    ]\n",
    "    g = [\n",
    "        self.gs[i][batch_id * self.batch_size:(batch_id + 1) * self.batch_size]\n",
    "        for i in range(self.ch_max_len)\n",
    "    ]\n",
    "    w = [\n",
    "        self.ws[i][batch_id * self.batch_size:(batch_id + 1) * self.batch_size]\n",
    "        for i in range(self.ch_max_len)\n",
    "    ]\n",
    "\n",
    "    return x, y, g, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = BatchGenerator(question_corpus, answer_corpus,vob['<PAD>'] ,vob['<PAD>'] ,question_corpus_max, \n",
    "                       answer_corpus_max,4)\n",
    "x, y, g, w = batch.get(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Come on, Jack, shall we go?!! <PAD> <PAD> <PAD> <PAD>\n",
      "<BEG> Apparently so. <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Apparently so. <END> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "Beware the moon? <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "<BEG> Come on, I'm freezing. <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Come on, I'm freezing. <END> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(' '.join([vob_rev[x[j][i]] for j in range(question_corpus_max)]))\n",
    "    print(' '.join([vob_rev[y[j][i]] for j in range(answer_corpus_max)]))\n",
    "    print(' '.join([vob_rev[g[j][i]] for j in range(answer_corpus_max)]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MachineTranslationSeq2Seq:\n",
    "    def __init__(self, en_max_len, ch_max_len, en_size, ch_size):\n",
    "        self.en_max_len = en_max_len\n",
    "        self.ch_max_len = ch_max_len\n",
    "        \n",
    "        with tf.variable_scope('seq2seq_intput/output'):\n",
    "            self.enc_inputs = [tf.placeholder(tf.int32, [None]) for i in range(en_max_len)] # time mojor feed\n",
    "            self.dec_inputs = [tf.placeholder(tf.int32, [None]) for i in range(ch_max_len)]\n",
    "            self.groundtruths = [tf.placeholder(tf.int32, [None]) for i in range(ch_max_len)]\n",
    "            self.weights = [tf.placeholder(tf.float32, [None]) for i in range(ch_max_len)]\n",
    "            \n",
    "        with tf.variable_scope('seq2seq_rnn'): # training by teacher forcing\n",
    "            self.out_cell = tf.contrib.rnn.LSTMCell(512)\n",
    "            self.outputs, _ = tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(self.enc_inputs, self.dec_inputs, \n",
    "                                                                                    self.out_cell, \n",
    "                                                                                    en_size, ch_size, 300)\n",
    "        with tf.variable_scope('seq2seq_rnn', reuse=True): # predict by feeding previous\n",
    "            self.pred_cell = tf.contrib.rnn.LSTMCell(512, reuse=True) # reuse cell for train and test\n",
    "            self.predictions, _ = tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(self.enc_inputs, self.dec_inputs, \n",
    "                                                                                        self.pred_cell, \n",
    "                                                                                        en_size, ch_size, 300, \n",
    "                                                                                        feed_previous=True)\n",
    "        \n",
    "        with tf.variable_scope('loss'):\n",
    "            # caculate weighted loss\n",
    "            self.loss = tf.reduce_mean(tf.contrib.legacy_seq2seq.sequence_loss_by_example(self.outputs, \n",
    "                                                                                          self.groundtruths, \n",
    "                                                                                          self.weights))\n",
    "            self.optimizer = tf.train.AdamOptimizer(0.002).minimize(self.loss)\n",
    "        \n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        self.sess = tf.Session(config=config)\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def train(self, x, y, g, w):\n",
    "        fd = {}\n",
    "        for i in range(self.en_max_len):\n",
    "            fd[self.enc_inputs[i]] = x[i] # show how to feed a list\n",
    "        \n",
    "        for i in range(self.ch_max_len):\n",
    "            fd[self.dec_inputs[i]] = y[i]\n",
    "            fd[self.groundtruths[i]] = g[i]\n",
    "            fd[self.weights[i]] = w[i]\n",
    "        \n",
    "        loss, _ = self.sess.run([self.loss, self.optimizer], fd)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def output(self, x, y):\n",
    "        fd = {}\n",
    "        for i in range(self.en_max_len):\n",
    "            fd[self.enc_inputs[i]] = x[i]\n",
    "        \n",
    "        for i in range(self.ch_max_len):\n",
    "            fd[self.dec_inputs[i]] = y[i]\n",
    "        \n",
    "        out = self.sess.run(self.outputs, fd)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def predict(self, x, ch_beg):\n",
    "        fd = {}\n",
    "        for i in range(self.en_max_len):\n",
    "            fd[self.enc_inputs[i]] = x[i]\n",
    "        \n",
    "        for i in range(self.ch_max_len): # when feed previous, the fist token should be '<BEG>', and others are useless\n",
    "            if i==0:\n",
    "                fd[self.dec_inputs[i]] = np.ones(y[i].shape, dtype=np.int32)*ch_beg\n",
    "            else:\n",
    "                fd[self.dec_inputs[i]] = np.zeros(y[i].shape, dtype=np.int32)\n",
    "        \n",
    "        pd = self.sess.run(self.predictions, fd)\n",
    "        \n",
    "        return pd\n",
    "    \n",
    "    def save(self, e):\n",
    "        self.saver.save(self.sess, 'model/seq2seq/seq2seq_%d.ckpt'%(e+1))\n",
    "    \n",
    "    def restore(self, e):\n",
    "        self.saver.restore(self.sess, 'model/seq2seq/seq2seq_%d.ckpt'%(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model = MachineTranslationSeq2Seq(question_corpus_max,answer_corpus_max,len(vob), len(vob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 256\n",
    "batch_num = len(question_corpus) // BATCH_SIZE\n",
    "\n",
    "batch = BatchGenerator(question_corpus, answer_corpus,vob['<PAD>'] ,vob['<PAD>'] ,question_corpus_max, \n",
    "                       answer_corpus_max,BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 10.492053\n",
      "epoch 1 loss: 9.448930\n",
      "epoch 2 loss: 6.858658\n",
      "epoch 3 loss: 5.612549\n",
      "epoch 4 loss: 5.288421\n",
      "epoch 5 loss: 5.061787\n",
      "epoch 6 loss: 4.903818\n",
      "epoch 7 loss: 4.591704\n",
      "epoch 8 loss: 4.281727\n",
      "epoch 9 loss: 3.961345\n",
      "epoch 10 loss: 3.676352\n",
      "epoch 11 loss: 3.335431\n",
      "epoch 12 loss: 2.940271\n",
      "epoch 13 loss: 2.575779\n",
      "epoch 14 loss: 2.194136\n",
      "epoch 15 loss: 1.894492\n",
      "epoch 16 loss: 1.623609\n",
      "epoch 17 loss: 1.460045\n",
      "epoch 18 loss: 1.226701\n",
      "epoch 19 loss: 1.016772\n",
      "Wall time: 13min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train seq2seq\n",
    "rec_loss = []\n",
    "for e in range(EPOCHS):\n",
    "    train_loss = 0\n",
    "    \n",
    "    for b in range(batch_num):\n",
    "        x, y, g, w = batch.get(b)\n",
    "        batch_loss = model.train(x, y, g, w)\n",
    "        train_loss += batch_loss\n",
    "    \n",
    "    train_loss /= batch_num\n",
    "    rec_loss.append(train_loss)\n",
    "    print(\"epoch %d loss: %f\" % (e, train_loss))\n",
    "    \n",
    "    model.save(e)\n",
    "    \n",
    "np.save('./model/seq2seq/rec_loss1.npy', rec_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#rec_loss = np.load('./model/seq2seq/rec_loss1.npy')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_loss = plt.plot([rec_loss[i] for i in range(len(rec_loss))])\n",
    "plt.legend(['Loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def cherry_pick(records, n, upper_bound=1.0):\n",
    "    bleus = []\n",
    "    \n",
    "    for en, ch_gr, ch_pd in records:\n",
    "        # caculate BLEU by nltk\n",
    "        bleu = nltk.translate.bleu_score.sentence_bleu([ch_gr], ch_pd)\n",
    "        bleus.append(bleu)\n",
    "    \n",
    "    lst = [i for i in range(len(records)) if bleus[i]<=upper_bound]\n",
    "    lst = sorted(lst, key=lambda i: bleus[i], reverse=True) # sort by BLEU score\n",
    "    \n",
    "    return [records[lst[i]] for i in range(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找出符合5個問題的set儲存起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['Hello.']\n",
      "['Where', 'are', 'you', 'going?']\n",
      "1\n",
      "['Where', 'are', 'you', 'going?']\n",
      "2\n",
      "['You', 'look', 'great.']\n",
      "['Good', 'night.']\n",
      "['Good', 'night.']\n",
      "['How', 'are', 'you?']\n"
     ]
    }
   ],
   "source": [
    "import random as rd\n",
    "\n",
    "records = []\n",
    "\n",
    "for i in range(batch_num):\n",
    "    print(i)\n",
    "    #i = rd.randint(0, batch_num - 1)  # random pick one to translate\n",
    "  \n",
    "    x, y, g, w = batch.get(i)\n",
    "    out = model.output(x, y)\n",
    "    pd = model.predict(x, vob['<BEG>'])\n",
    "    \n",
    "    for j in range(256):\n",
    "        #j = rd.randint(0, BATCH_SIZE - 1)\n",
    "        en = [vob_rev[x[k][j]] for k in range(question_corpus_max)]\n",
    "        en = en[:en.index('<PAD>')]\n",
    "        if (['Hello.'] == en)|(['How','are','you?']== en)|(['Where','are','you','going?']== en)| (['You','look','great.'] == en)|(['Good','night.'] == en)  :\n",
    "            print(en)\n",
    "            ch_gr = [vob_rev[g[k][j]] for k in range(answer_corpus_max)]\n",
    "            if '<END>' in ch_gr:\n",
    "                ch_gr = ch_gr[:ch_gr.index('<END>')]\n",
    "            ch_pd = [vob_rev[np.argmax(pd[i][j, :])] for i in range(answer_corpus_max)]\n",
    "            if '<END>' in ch_pd:\n",
    "                ch_pd = ch_pd[:ch_pd.index('<END>')]\n",
    "\n",
    "            records.append([en, ch_gr, ch_pd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good boy. <PAD> <PAD>\n",
      "Jack. <END> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "#測試\n",
    "#len(batch.get(2))\n",
    "#a1 = 0\n",
    "#a2 = 2\n",
    "#a3 = 21\n",
    "#\n",
    "#print(vob_rev[batch.get(a1)[0][a2][a3]]+' '+vob_rev[batch.get(a1)[0][a2+1][a3]]+' '+vob_rev[batch.get(a1)[0][a2+2][a3]]+' '+\\\n",
    "#vob_rev[batch.get(a1)[0][a2+3][a3]])\n",
    "#\n",
    "#print(vob_rev[batch.get(a1)[2][a2][a3]]+' '+vob_rev[batch.get(a1)[2][a2+1][a3]]+' '+vob_rev[batch.get(a1)[2][a2+2][a3]]+' '+\\\n",
    "#vob_rev[batch.get(a1)[2][a2+3][a3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input\n",
      "Ground truth\n",
      "Decoder output\n",
      "\n",
      "Where are you going?\n",
      "I'm just leaving.\n",
      "I'm just leaving.\n",
      "\n",
      "Where are you going?\n",
      "I'm just leaving.\n",
      "I'm just leaving.\n",
      "\n",
      "How are you?\n",
      "Another young man.\n",
      "Another young man.\n",
      "\n",
      "Good night.\n",
      "Good night.\n",
      "Good night.\n",
      "\n",
      "Good night.\n",
      "Good night.\n",
      "Good night.\n",
      "\n",
      "You look great.\n",
      "Thanks.\n",
      "Thanks.\n",
      "\n",
      "Hello.\n",
      "Nice to see you.\n",
      "You crucifying you.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stat_pc\\Anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\stat_pc\\Anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\stat_pc\\Anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoder input\")\n",
    "print(\"Ground truth\")\n",
    "print(\"Decoder output\")\n",
    "print()\n",
    "\n",
    "n = len(records)  # how many result we show\n",
    "rec_cherry = cherry_pick(records, n)\n",
    "\n",
    "for i in range(n):\n",
    "  for j in range(3):\n",
    "    print(' '.join(rec_cherry[i][j]))\n",
    "\n",
    "  print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "\n",
    "1.首先先做資料清理，清洗完後按照之前第一次比賽的邏輯把資料count起來算idf。\n",
    "\n",
    "\n",
    "2.由於有指定需要的5個問題，先在train的地方確保這些字有在裡面。\n",
    "\n",
    "\n",
    "3.在seq2seq嘗試了許多次 發現epoch其實不用太高train在loss的反應上表現就不錯了\n",
    "\n",
    "\n",
    "4.資料清洗的地方做得還不夠徹底，導致train太多資料時電腦當機了許多次。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
